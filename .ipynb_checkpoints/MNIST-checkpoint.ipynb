{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "# fix random seed for reproducibility\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from pandas.tools.plotting import parallel_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "\n",
    "To download the sataset from the web follow this is the link https://archive.ics.uci.edu/ml/datasets/Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been loaded\n"
     ]
    }
   ],
   "source": [
    "# Link to data on the disk\n",
    "raw_data = np.genfromtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", delimiter=',')\n",
    "print('The dataset has been loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of features , number of examples =  (4601, 58)\n"
     ]
    }
   ],
   "source": [
    "# print(the number of examples and the dimenstion in this dataset\n",
    "# Notice that the last feature in this dataset is the target\n",
    "data = raw_data\n",
    "size = np.shape(data)\n",
    "print(' Number of features , number of examples = ', size)\n",
    "np.random.shuffle(data)\n",
    "X = data[:, 0:-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# for training data\n",
    "X = dataset.astype(float)\n",
    "features = preprocessing.scale(X)\n",
    "target = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 57)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Extracting 20% validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.40, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproccing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 2760\n",
      "Number of validation examples 1841\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples',len(X_train))\n",
    "print('Number of validation examples',len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# normalize the data attributes\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "#X_test = preprocessing.normalize(X_test)\n",
    "# standardize the data attributes\n",
    "X_train = preprocessing.scale(X_train)\n",
    "#X_test = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for training NN is  404.13883900642395 seconds \n",
      "Test fraction correct (NN-loss) = 0.09\n",
      "Test fraction correct (NN-Accuracy) = 0.97\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "# The layers where we want to prune\n",
    "N1 = 20\n",
    "N2 = 20\n",
    "labelsTrain = np_utils.to_categorical(y_train)\n",
    "model = Sequential()\n",
    "model.add(Dense(N1,\n",
    "                input_shape=(57,), \n",
    "                activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(N2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "start_time = time.time()\n",
    "model.fit(X_train, labelsTrain, verbose=0, batch_size=1, epochs=100)\n",
    "print(\"The time for training NN is  %s seconds \" % (time.time() - start_time))\n",
    "loss, accuracy = model.evaluate(X_train, labelsTrain, batch_size=1, verbose=0)\n",
    "print(\"Test fraction correct (NN-loss) = {:.2f}\".format(loss))\n",
    "print(\"Test fraction correct (NN-Accuracy) = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBuckup = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                1160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 1,622\n",
      "Trainable params: 1,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelBuckup.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Method for Pruning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the layer should have N1 and N2 weights\n",
    "L = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  2944.9264500141144\n"
     ]
    }
   ],
   "source": [
    "startD = time.time()\n",
    "N_arry = np.zeros((N1*N2))\n",
    "N_arryD = np.zeros((N1*N2))\n",
    "noExamples = len(X_train)\n",
    "NL = np.zeros(noExamples)\n",
    "Threshold = 0\n",
    "constant=1\n",
    "for k in range(noExamples):\n",
    "    count = 0\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[k:k+1], labelsTrain[k:k+1], \n",
    "                                                 batch_size=1, verbose=0)\n",
    "        # Prune the neuron in the layer\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[L][i][j]\n",
    "            All_weights[L][i][j] = 0\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[k:k+1], labelsTrain[k:k+1], \n",
    "                                                         batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            #reward = max(0,Threshold + delta)/constant\n",
    "            #print('delta = ', delta)\n",
    "            All_weights[L][i][j]= temp  # before\n",
    "            N_arry[count] = max(delta,0) \n",
    "            count = count +1\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "                #print(delta)\n",
    "    NL[k]=np.argmax(N_arry) # chosen weight at every iteration\n",
    "    N_arryD = N_arryD + N_arry \n",
    "endD = time.time()\n",
    "print(\"Execution time \",endD - startD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The single weight that has been chosen by direct method\n",
    "\n",
    "Practically we choose k weights that have high rewards but the purpose of this file to show the computation time and which is the method be able to choose best arm comparing to direct method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of chosen  W_ji is =  13 11\n"
     ]
    }
   ],
   "source": [
    "reshapeD = N_arryD.reshape(N1,N2)\n",
    "D = np.argmax(N_arryD)\n",
    "Di,Dj = np.unravel_index(D, reshapeD.shape)\n",
    "print(\"The index of chosen  W_ji is = \", Dj, Di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilon Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 1900  # will be the same for all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  9.05153512954712\n"
     ]
    }
   ],
   "source": [
    "startG = time.time()\n",
    "N_arry = np.zeros(N1*N2)\n",
    "#noExamples = 100\n",
    "NL = np.zeros(Round)\n",
    "ep = np.zeros(Round)\n",
    "Avg_Accumaltive_R_EGN = np.zeros(N1*N2)\n",
    "p_reshape = Avg_Accumaltive_R_EGN.reshape(N1,N2)\n",
    "Count_EGN = np.ones(N1*N2)\n",
    "import random\n",
    "epsilon=0.5\n",
    "count = 0\n",
    "for i in range(N1): \n",
    "    for j in range(N2):\n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[1:10], labelsTrain[1:10], batch_size=1, verbose=0)\n",
    "        # Prune the neuron in the layer\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[2][i][j]\n",
    "            All_weights[2][i][j] = 0 \n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[1:10], labelsTrain[1:10], batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            reward = max(0,Threshold + delta)/constant\n",
    "            All_weights[2][i][j]= temp\n",
    "            Avg_Accumaltive_R_EGN[count] = reward\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            count = count+1\n",
    "for j in range(N1+N2-1, Round):\n",
    "            b = random.randint(0,noExamples-1)  \n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "        # Prune the neuron in the layer\n",
    "            if (epsilon>random.uniform(0, 1)):\n",
    "                ind = np.argmax(Avg_Accumaltive_R_EGN)\n",
    "            else:\n",
    "                ind = random.randint(0,N1*N2-1)\n",
    "            i,k = np.unravel_index(ind, p_reshape.shape)\n",
    "            #print(i,k)\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[2][i][k]\n",
    "            All_weights[2][i][k] = 0\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            Count_EGN[ind]=Count_EGN[ind]+1\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            #print(delta)\n",
    "            reward = max(0,Threshold + delta)/constant\n",
    "            #print(reward)\n",
    "            val = Count_EGN[ind]\n",
    "            Avg_Accumaltive_R_EGN[ind] = (val-1)/val * Avg_Accumaltive_R_EGN[ind] + 1/val * reward\n",
    "            All_weights[2][i][k] = temp\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            ep[j]=ind\n",
    "endG = time.time()\n",
    "print(\"Execution time \",endG - startG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The single weight that has been chosen by Epsilon Greedy method\n",
    "\n",
    "Practically we choose k weights that have high rewards but the purpose of this file to show the computation time and which is the method be able to choose best arm comparing to direct method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of chosen  W_ji is =  12 9\n"
     ]
    }
   ],
   "source": [
    "reshapeG = Avg_Accumaltive_R_EGN.reshape(N1,N2)\n",
    "G = np.argmax(Avg_Accumaltive_R_EGN)\n",
    "Gi,Gj = np.unravel_index(G, reshapeG.shape)\n",
    "print(\"The index of chosen  W_ji is = \", Gj, Gi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  9.791861057281494\n"
     ]
    }
   ],
   "source": [
    "startU = time.time()\n",
    "N_arry = np.zeros(N1*N2)\n",
    "NL = np.zeros(Round)\n",
    "Avg_Accumaltive_UCB = np.zeros(N1*N2)\n",
    "Count_UCB = np.ones(N1*N2)\n",
    "UCB1 = np.zeros(Round)\n",
    "p_reshape = Avg_Accumaltive_UCB.reshape(N1,N2)\n",
    "count = 0\n",
    "import random\n",
    "tau=4\n",
    "for i in range(N1): \n",
    "    for j in range(N2):\n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[1:10], labelsTrain[1:10], batch_size=1, verbose=0)\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[2][i][j]\n",
    "            All_weights[2][i][j] = 0 \n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[1:10], labelsTrain[1:10], batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            reward = max(0,Threshold + delta)/constant\n",
    "            All_weights[2][i][j]= temp\n",
    "            Avg_Accumaltive_UCB[count] = reward\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            count = count+1\n",
    "for j in range(N1+N2-1, Round):\n",
    "            b = random.randint(0,noExamples-1)  \n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "            padding = np.sqrt(2*Count_UCB.sum()/Count_UCB)\n",
    "            ucb = Avg_Accumaltive_UCB + padding\n",
    "            ind = np.argmax(ucb)\n",
    "            Count_UCB[ind] = Count_UCB[ind] + 1\n",
    "            i,k = np.unravel_index(ind, p_reshape.shape)\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[2][i][k]\n",
    "            All_weights[2][i][k] = 0           \n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            reward = max(0,Threshold + delta)/constant\n",
    "            All_weights[2][i][k] = temp\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            val = Count_UCB[ind]\n",
    "            Avg_Accumaltive_UCB[ind] = (val-1)/val * Avg_Accumaltive_UCB[ind] + 1/val * reward\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            UCB1[j]=ind\n",
    "endU = time.time()\n",
    "print(\"Execution time \",endU - startU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The single weight that has been chosen by UCB1 method\n",
    "\n",
    "Practically we choose k weights that have high rewards but the purpose of this file to show the computation time and which is the method be able to choose best arm comparing to direct method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of chosen  W_ji is =  12 9\n"
     ]
    }
   ],
   "source": [
    "reshapeU = Avg_Accumaltive_UCB.reshape(N1,N2)\n",
    "U = np.argmax(Avg_Accumaltive_UCB)\n",
    "Ui,Uj = np.unravel_index(U, reshapeU.shape)\n",
    "print(\"The index of chosen  W_ji is = \", Uj, Ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  10.472270011901855\n"
     ]
    }
   ],
   "source": [
    "startT = time.time()\n",
    "N_arry = np.zeros(N1*N2)\n",
    "NL = np.zeros(Round)\n",
    "Avg_Accumaltive_TS = np.zeros(N1*N2)\n",
    "Count_TS = np.ones(N1*N2)\n",
    "TS = np.zeros(Round)\n",
    "p_reshape = Avg_Accumaltive_TS.reshape(N1,N2)\n",
    "count = 0\n",
    "success = np.zeros(N1*N2)\n",
    "failure = np.zeros(N1*N2)\n",
    "for i in range(N1): \n",
    "    for j in range(N2):\n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[1:10], labelsTrain[1:10], batch_size=1, verbose=0)\n",
    "        # Prune the neuron in the layer\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[2][i][j]\n",
    "            All_weights[2][i][j] = 0 \n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[1:10], labelsTrain[1:10], batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            if(delta>0):\n",
    "                reward = 1\n",
    "                success[i] = success[i]+1\n",
    "            else:\n",
    "                reward = 0\n",
    "                failure[i] = failure[i]+1                        \n",
    "            All_weights[2][i][j]= temp\n",
    "            Avg_Accumaltive_TS[count] = reward\n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            count = count+1\n",
    "for j in range(N1+N2-1, Round):\n",
    "            b = random.randint(0,noExamples-1)  \n",
    "            loss, accuracy = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "        # Prune the neuron in the layer \n",
    "            ind = np.argmax(np.random.beta(1+success, 1+failure))\n",
    "            Count_TS[ind] = Count_TS[ind] + 1\n",
    "            i,k = np.unravel_index(ind, p_reshape.shape)\n",
    "            All_weights=modelBuckup.get_weights()\n",
    "            temp = All_weights[2][i][k]\n",
    "            All_weights[2][i][k] = 0                     \n",
    "            modelBuckup.set_weights(All_weights)\n",
    "            loss_New, accuracy_New = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "            delta = loss_New - loss\n",
    "            if(delta>0):\n",
    "                reward = 1\n",
    "                success[i] = success[i]+1\n",
    "            else:\n",
    "                reward = 0\n",
    "                failure[i] = failure[i]+1            \n",
    "            All_weights[2][i][k] = temp\n",
    "            modelBuckup.set_weights(All_weights)          \n",
    "            val = Count_TS[ind]\n",
    "            Avg_Accumaltive_TS[ind] = (val-1)/val * Avg_Accumaltive_TS[ind] + 1/val * reward\n",
    "            TS[j]=ind\n",
    "endT = time.time()\n",
    "print(\"Execution time \",endT - startT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The single weight that has been chosen by Thompson Sampling method\n",
    "\n",
    "Practically we choose k weights that have high rewards but the purpose of this file to show the computation time and which is the method be able to choose best arm comparing to direct method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of chosen  W_ji is =  2 3\n"
     ]
    }
   ],
   "source": [
    "reshapeT = Avg_Accumaltive_TS.reshape(N1,N2)\n",
    "T = np.argmax(Avg_Accumaltive_TS)\n",
    "Ti,Tj = np.unravel_index(T, reshapeT.shape)\n",
    "print(\"The index of chosen  W_ji is = \", Tj, Ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Successive Rejects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a K-armed bandit, Successive Rejects operates in (K − 1) phases. At the end of each phase, the arm with the lowest average reward is discarded. Thus, at the end of phase (K − 1) only one arm survives, and this arm is recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  113.61265087127686\n",
      "A =  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 19, 20, 22, 24, 27, 30, 35, 41, 49, 61, 82]\n",
      "Nk =  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 2, 3, 3, 5, 6, 8, 12, 21]\n"
     ]
    }
   ],
   "source": [
    "startS = time.time()\n",
    "N_arry = np.zeros(N1*N2)\n",
    "NL = np.zeros(noExamples)\n",
    "sr = []\n",
    "Avg_Accumaltive_SR = np.zeros(N1*N2)\n",
    "Avg_Accumaltive_SR2 = np.zeros(N1*N2)\n",
    "Avg_Accumaltive_SR1 = np.zeros(N1*N2)\n",
    "p_reshape = Avg_Accumaltive_SR2.reshape(N1,N2)\n",
    "check_array = np.ones((N1,N2))\n",
    "Count_SR = np.ones(N1*N2)\n",
    "A = [0]\n",
    "Nk = []\n",
    "K = N1*N2\n",
    "Log = 0.5\n",
    "for k in range(K):\n",
    "    d = k+2\n",
    "    Log = Log + 1/d\n",
    "for k in range(K-2):\n",
    "    d = k+1\n",
    "    nK = int(np.floor(1/Log * (Round-K)/(K+1-d)))\n",
    "    if nK!=0:\n",
    "        A.append(nK)\n",
    "A.sort(reverse=False)\n",
    "#print(\"The round of the phases : \",A)\n",
    "g=0\n",
    "for a in A:\n",
    "    h = a - g\n",
    "    g = a\n",
    "    Nk.append(h)\n",
    "    count=0\n",
    "    #print(a)\n",
    "    for n in range(h):\n",
    "        c=0\n",
    "        for i in range(N1):\n",
    "            for j in range(N2):\n",
    "                if check_array[i][j]==1:\n",
    "                    b = random.randint(0,noExamples-1) \n",
    "                    loss, accuracy = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "                    All_weights=modelBuckup.get_weights()\n",
    "                    temp = All_weights[2][i][j]\n",
    "                    All_weights[2][i][j] = 0\n",
    "                    modelBuckup.set_weights(All_weights)\n",
    "                    loss_New, accuracy_New = modelBuckup.evaluate(X_train[b:b+1], labelsTrain[b:b+1], batch_size=1, verbose=0)\n",
    "                    delta = loss_New - loss\n",
    "                    reward = max(0,Threshold + delta)/constant\n",
    "                    All_weights[2][i][j] = temp\n",
    "                    modelBuckup.set_weights(All_weights)\n",
    "                    val = Count_SR[c]\n",
    "                    #print(reward)\n",
    "                    Avg_Accumaltive_SR[c] = (val-1)/val * Avg_Accumaltive_SR[c] + 1/val * reward\n",
    "                    All_weights[2][i][j] = temp\n",
    "                    modelBuckup.set_weights(All_weights)\n",
    "                    count = count+1\n",
    "                    c = c + 1    \n",
    "        Avg_Accumaltive_SR2=Avg_Accumaltive_SR2+Avg_Accumaltive_SR\n",
    "        Avg_Accumaltive_SR1=Avg_Accumaltive_SR2.copy()\n",
    "    ind = np.argmin(Avg_Accumaltive_SR2)\n",
    "    Avg_Accumaltive_SR2[ind] = 100\n",
    "    #print(Avg_Accumaltive_SR)\n",
    "    s,t = np.unravel_index(ind, p_reshape.shape)\n",
    "    ###check_array[s][t]=0\n",
    "    sr.append(ind)\n",
    "endS = time.time()\n",
    "print(\"Execution time \",endS - startS)\n",
    "print(\"A = \", A)\n",
    "print(\"Nk = \", Nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_Accumaltive_SR3 = np.abs(100-Avg_Accumaltive_SR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The single weight that has been chosen by Successive Rejects method\n",
    "\n",
    "Practically we choose k weights that have high rewards but the purpose of this file to show the computation time and which is the method be able to choose best arm comparing to direct method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of chosen  W_ji is =  14 15\n"
     ]
    }
   ],
   "source": [
    "reshapeS = Avg_Accumaltive_SR3.reshape(N1,N2)\n",
    "S = np.argmax(Avg_Accumaltive_SR3)\n",
    "Si,Sj = np.unravel_index(S, reshapeS.shape)\n",
    "print(\"The index of chosen  W_ji is = \", Sj, Si)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewards in each method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\" \\nReward of Direct Method :\")\n",
    "print(N_arryD)\n",
    "print(\" \\nReward of Epsilon Greey Method :\")\n",
    "print(Avg_Accumaltive_R_EGN)\n",
    "print(\" \\nReward of UCB Method :\")\n",
    "print(Avg_Accumaltive_UCB)\n",
    "print(\" \\nReward of Thompson Sampling Method :\")\n",
    "print(Avg_Accumaltive_TS)\n",
    "print(\" \\nReward of Successive Rejects Method :\")\n",
    "print(Avg_Accumaltive_SR3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution time for different method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of Direct Method             = 2944.9264500141144\n",
      "Execution time of Epsilon Greedy Method     = 9.05153512954712\n",
      "Execution time of UCB1 Method               = 9.791861057281494\n",
      "Execution time of Thompson Sampling Method  = 10.472270011901855\n",
      "Execution time of Successive Rejects Method = 113.61265087127686\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution time of Direct Method             =\",endD - startD)\n",
    "print(\"Execution time of Epsilon Greedy Method     =\",endG - startG)\n",
    "print(\"Execution time of UCB1 Method               =\",endU - startU)\n",
    "print(\"Execution time of Thompson Sampling Method  =\",endT - startT)\n",
    "print(\"Execution time of Successive Rejects Method =\",endS - startS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Spearman’s rank correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method has been used in the paper [1] (ICLR 2017 paper from NVIDIA) to compare the different pruning methods compare to the direct (oracle) method as following:\n",
    "\n",
    "Given the difference between the direct method and other method, $ d_i = rank(\\theta _d(i) - rand( \\theta _{other}(i))$ for each parameter $i$, the rank correlation is computer:\n",
    "\n",
    "$ S = 1 - \\frac{6}{N(N^2-1)} \\sum_{i=1}^{N} d_{i}^{2}$\n",
    "\n",
    "\n",
    "\n",
    "[1] https://arxiv.org/pdf/1611.06440.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D = pd.DataFrame({\"Weights_Direct\":N_arryD})\n",
    "df_G = pd.DataFrame({\"Weights_E_Greedy\":Avg_Accumaltive_R_EGN})\n",
    "df_U = pd.DataFrame({\"Weights_UCB\":Avg_Accumaltive_UCB}) \n",
    "df_T = pd.DataFrame({\"Weights_TS\":Avg_Accumaltive_TS}) \n",
    "df_S = pd.DataFrame({\"Weights_SR\":Avg_Accumaltive_SR3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_D[\"Direct Rank\"] = df_D.rank(method='max')\n",
    "df_G[\"E_Greedy Rank\"] = df_G.rank(method='max')\n",
    "df_U[\"UCB Rank\"] = df_U.rank(method='max')\n",
    "df_T[\"TS Rank\"] = df_T.rank(method='max')\n",
    "df_S[\"SR Rank\"] = df_S.rank(method='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D[\"Direct Rank\"] = df_D.rank()\n",
    "df_G[\"E_Greedy Rank\"] = df_G.rank()\n",
    "df_U[\"UCB Rank\"] = df_U.rank()\n",
    "df_T[\"TS Rank\"] = df_T.rank()\n",
    "df_S[\"SR Rank\"] = df_S.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D[\"d E_Greedy\"] = df_D[\"Direct Rank\"] - df_G[\"E_Greedy Rank\"]\n",
    "df_D[\"d UCB\"] = df_D[\"Direct Rank\"] - df_U[\"UCB Rank\"]\n",
    "df_D[\"d TS\"] = df_D[\"Direct Rank\"] - df_T[\"TS Rank\"]\n",
    "df_D[\"d SR\"] = df_D[\"Direct Rank\"] - df_S[\"SR Rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D[\"d square E_Greedy\"] = df_D[\"d E_Greedy\"] * df_D[\"d E_Greedy\"]\n",
    "df_D[\"d square UCB\"] = df_D[\"d UCB\"] * df_D[\"d UCB\"]\n",
    "df_D[\"d square TS\"] = df_D[\"d TS\"] * df_D[\"d TS\"]\n",
    "df_D[\"d square SR\"] = df_D[\"d SR\"] * df_D[\"d SR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_E_greedy = 1 - 6/(N1*N2*((N1*N2)**2 - 1)) * df_D[\"d square E_Greedy\"].sum()\n",
    "S_UCB = 1 - 6/(N1*N2*((N1*N2)**2 - 1)) * df_D[\"d square UCB\"].sum()\n",
    "S_TS = 1 - 6/(N1*N2*((N1*N2)**2 - 1)) * df_D[\"d square TS\"].sum()\n",
    "S_SR = 1 - 6/(N1*N2*((N1*N2)**2 - 1)) * df_D[\"d square SR\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name of Method': [\"Epsilon Greedy\", \"UCB1\", \"Thompson Sampling\", \"Successive Rejects\"], 'Spearman rank correlation': [S_E_greedy, S_UCB, S_TS, S_SR]}\n",
    "df_cor = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Method</th>\n",
       "      <th>Spearman rank correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epsilon Greedy</td>\n",
       "      <td>0.458360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCB1</td>\n",
       "      <td>0.472880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thompson Sampling</td>\n",
       "      <td>0.448124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Successive Rejects</td>\n",
       "      <td>0.333845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name of Method  Spearman rank correlation\n",
       "0      Epsilon Greedy                   0.458360\n",
       "1                UCB1                   0.472880\n",
       "2   Thompson Sampling                   0.448124\n",
       "3  Successive Rejects                   0.333845"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cor.plot.bar(x='Name of Method', y='Spearman rank correlation', rot=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
